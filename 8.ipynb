{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "173662d9",
   "metadata": {},
   "source": [
    "The softmax activation function is primarily used in the output layer of a neural network for multi-class classification tasks. Its purpose is to convert the raw output scores (often called logits) of a neural network into probabilities that sum up to 1, representing the likelihood of each class.\n",
    "\n",
    "Mathematically, the softmax function is defined as follows:\n",
    "\n",
    "softmax\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "=\n",
    "�\n",
    "�\n",
    "�\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    "softmax(z \n",
    "i\n",
    "​\n",
    " )= \n",
    "∑ \n",
    "j=1\n",
    "K\n",
    "​\n",
    " e \n",
    "z \n",
    "j\n",
    "​\n",
    " \n",
    " \n",
    "e \n",
    "z \n",
    "i\n",
    "​\n",
    " \n",
    " \n",
    "​\n",
    " \n",
    "\n",
    "Where:\n",
    "\n",
    "�\n",
    "�\n",
    "z \n",
    "i\n",
    "​\n",
    "  is the raw output score (logit) for class \n",
    "�\n",
    "i.\n",
    "�\n",
    "K is the total number of classes.\n",
    "The function exponentiates the raw scores and divides each exponentiated score by the sum of all exponentiated scores, ensuring that the resulting values are normalized and sum up to 1.\n",
    "The softmax function produces a probability distribution over the classes, making it suitable for multi-class classification tasks where the model needs to predict the probability of each class given an input.\n",
    "\n",
    "Softmax is commonly used in scenarios such as:\n",
    "\n",
    "Multi-Class Classification: When the task involves classifying input data into more than two classes (e.g., image classification with multiple categories, sentiment analysis with multiple sentiment labels).\n",
    "Output Layer of Neural Networks: Softmax is typically applied in the output layer of neural networks to convert the network's raw output into probabilities, allowing for easy interpretation of the model's predictions.\n",
    "Cross-Entropy Loss Calculation: Softmax is often used in conjunction with the cross-entropy loss function for training neural networks on multi-class classification tasks. The cross-entropy loss measures the difference between the predicted probability distribution and the true distribution of class labels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
